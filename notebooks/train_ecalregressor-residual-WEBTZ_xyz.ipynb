{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import torch\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from tqdm import tqdm as tqdm\n",
    "#from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"pyg:\",torch_geometric.__version__)\n",
    "print(\"torch:\",torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_scale=50.\n",
    "m0_scale=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_y(y):\n",
    "    return (y)/m0_scale\n",
    "\n",
    "def inv_transform(y):\n",
    "    return (y*m0_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_list_pi=[]\n",
    "raw_dir= '/export/home/phys/aharilal/MassRegressor/a2gg-regression/GNNscripts/GNNDATA/Pi0_graphs/Pi0_UL17/EBTZ_rwcl_xyz/*/'\n",
    "fnamelistt = [filepath for filepath in glob.glob(raw_dir+'data*.pt')]\n",
    "for i in tqdm(fnamelistt):\n",
    "    idx = torch.load(i)\n",
    "    idx.genmass = transform_y(idx.pmass)\n",
    "    #print(idx.genmass)\n",
    "    #idx.X= idx.x\n",
    "    #print(idx.x.shape)\n",
    "    idx.x[:,0]=idx.x[:,0]/eb_scale\n",
    "    idx.x[:,1]=idx.x[:,1]/eb_scale\n",
    "    #idx.x[:,2]=idx.x[:,2] + idx.pscieta\n",
    "    #idx.x[:,3]=idx.x[:,3] + idx.psciphi\n",
    "    data_list_pi.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pmass, pscieta, psciphi : tensor names\n",
    "# import pho data\n",
    "hi,lo = -2., 0.\n",
    "\n",
    "\n",
    "import glob\n",
    "raw_dir= '/export/home/phys/aharilal/MassRegressor/a2gg-regression/GNNscripts/GNNDATA/Gamma_graphs/Gamma_UL17/EBTZ_rwcl_xyz/0000/'#'/data_CMS/cms/sghosh/ECALGNNDATA/GRAPHS_ietaiphi/GenGamma/'\n",
    "fnamelist = [filepath for filepath in glob.glob(raw_dir+'data*.pt')]\n",
    "data_list_pho = []\n",
    "ctr = 0\n",
    "for i in tqdm(fnamelist):\n",
    "    idx = torch.load(i)\n",
    "    idx.genmass =  torch.tensor((hi-lo)*np.random.random_sample(size=(1,1)) + lo , dtype=torch.float32)\n",
    "    #print(idx.genmass)\n",
    "    #idx.x[] = idx.x\n",
    "    idx.x[:,0] = idx.x[:,0]/eb_scale\n",
    "    idx.x[:,1] = idx.x[:,1]/eb_scale\n",
    "    #idx.x[:,2]=idx.x[:,2] + idx.pscieta\n",
    "    #idx.x[:,3]=idx.x[:,3] + idx.psciphi\n",
    "    idx.genmass = transform_y(idx.genmass)\n",
    "    #print(idx.genmass)\n",
    "    \n",
    "    data_list_pho.append(idx)\n",
    "    #data_list.append(torch.load(i))\n",
    "    \n",
    "    if ctr > 71000 :\n",
    "        break\n",
    "    ctr +=1\n",
    "        \n",
    "        \n",
    "print(data_list_pho[0].pmass,data_list_pho[0].genmass)\n",
    "totalevpho = len(data_list_pho)\n",
    "#trainev ='''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir='/export/home/phys/aharilal/MassRegressor/a2gg-regression/PLOTS/GNN_plots/UL17_GNN_scale50_WEBTZ_rwcl_xyz'\n",
    "#for d in ['MODELS','PLOTS']:\n",
    "if not os.path.isdir(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "\n",
    "checkpoint_dir = '/export/home/phys/aharilal/MassRegressor/a2gg-regression/MODELS/UL17_GNN_scale50_WEBTZ_rwcl_xyz'\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del data_list_comb\n",
    "trainfrac = 0.8\n",
    "\n",
    "totalevpi = len(data_list_pi)\n",
    "trainpi =  int(0.8*totalevpi) #151000\n",
    "\n",
    "trainpho = int(0.8*len(data_list_pho)) #27768  #int((trainpi/18.0)*(lo-hi))*2\n",
    "\n",
    "print(\"totalevpi, trainpi, trainpho :\",totalevpi,trainpi,trainpho)\n",
    "\n",
    "import random\n",
    "\n",
    "data_list_photest = data_list_pho  #[]\n",
    "random.shuffle(data_list_pi)\n",
    "data_list_train = data_list_pi[:trainpi] + data_list_photest[:trainpho]\n",
    "random.shuffle(data_list_train)\n",
    "totaltrain = len(data_list_train)\n",
    "print(\"total train evs:\",totaltrain)\n",
    "\n",
    "\n",
    "valpi = len(data_list_pi[trainpi:]) #32895\n",
    "valpho = len(data_list_pho[trainpho:]) #3086#3000##int((valpi/18.0)*(lo-hi))\n",
    "\n",
    "data_list_val = data_list_pi[trainpi:] #+ data_list_photest[trainpho:trainpho+valpho]\n",
    "\n",
    "print(\"valpi,valpho,len(data_list_val) :\",valpi,valpho,len(data_list_val))\n",
    "\n",
    "\n",
    "import torch_geometric\n",
    "ntrainbatch = 200\n",
    "ntestbatch = 200\n",
    "trainloader = torch_geometric.data.DataLoader(data_list_train, batch_size=ntrainbatch)\n",
    "testloader = torch_geometric.data.DataLoader(data_list_val, batch_size=ntestbatch)\n",
    "#batch_size = ntrainbatch\n",
    "epoch_size = len(data_list_train)\n",
    "print(\"epoch size,batch_size:\",epoch_size,ntrainbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "#from tqdm import tqdm as tqdm\n",
    "\n",
    "from models.GNN_DRN import DynamicReductionNetwork\n",
    "from utils.load_scheduler import CyclicLRWithRestarts\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.drn = DynamicReductionNetwork(input_dim=7,hidden_dim=40,k=16,output_dim=1,norm=torch.tensor([1.,1., 1./64., 1./64.,1./64., 1./64., 1./64.]))\n",
    "        \n",
    "    def forward(self, data):\n",
    "        logits = self.drn(data)\n",
    "        #return F.softplus(logits)\n",
    "        return logits\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-3)\n",
    "scheduler = CyclicLRWithRestarts(optimizer, ntrainbatch, epoch_size, restart_period=80, t_mult=1.2, policy=\"cosine\")\n",
    "#criterion = torch.nn.MSELoss()\n",
    "\n",
    "#lossmse = nn.MSELoss()\n",
    "def resoloss2(output,truth):\n",
    "    batch_size = output.size()[0]\n",
    "    #mse = F.mse_loss(output, truth, reduction='mean')\n",
    "    #mse = torch.sum((output-truth)**2/truth)/batch_size\n",
    "    #mse = torch.sum(((output-truth)/truth)**2)/batch_size\n",
    "    mse = torch.mean(torch.abs((output - truth)))\n",
    "    \n",
    "    #res = \n",
    "    return (mse)\n",
    "\n",
    "\n",
    "#model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    scheduler.step()\n",
    "    loss = []\n",
    "    for data in tqdm(trainloader):\n",
    "            #print(\"\\n\\nScaled data: \")\n",
    "            #print(data.X[:,0].flatten())\n",
    "            #print(\"\\n Unscaled data: \")\n",
    "            #print(data.x[:,0].flatten())\n",
    "            data = data.to(device)\n",
    "            #print(\"\\n train data= \", data)\n",
    "            optimizer.zero_grad()\n",
    "            result = inv_transform(model(data))\n",
    "            truthv = inv_transform(data.genmass.flatten())\n",
    "            #print(\"train result: \",result)\n",
    "            #print(\"original mass: \",truthv)\n",
    "            lossc = resoloss2(result, truthv)\n",
    "            #print(\"result:\",result)\n",
    "            #print(\"truth:\",data.z)\n",
    "            #lossc = categorical_loss(result, data.z, 1.0)\n",
    "#            lossc = categorical_loss_only(result, data.z)\n",
    "#            mse = F.mse_loss(result, data.y, reduction='mean')\n",
    "#            mse = criterion(result, data.y)\n",
    "#            print('result, y:',result,data.y)\n",
    "#            print('crit, orig:',criterion(result, data.y),F.mse_loss(result, data.y, reduction='mean'))\n",
    "            loss.append(lossc.item()) \n",
    "            lossc.backward()\n",
    "#            print(mse)\n",
    "            optimizer.step()\n",
    "            scheduler.batch_step()\n",
    "    print( 'batches for train:',len(loss)) \n",
    "#    print('loss',loss)\n",
    "    print('train loss:',np.mean(np.array(loss)))\n",
    "    return np.mean(np.array(loss))\n",
    "    #del loss #memtest\n",
    "#    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import matplotlib.mlab as mlab\n",
    "import scipy.stats as scs\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "def gaussian(x,  mean,a, sigma):\n",
    "    return a * np.exp(-((x - mean)**2 / (2 * sigma**2)))\n",
    "\n",
    "def evaluate(epoch):\n",
    "        \"\"\"\"Evaluate the model\"\"\"\n",
    "        model.zero_grad()\n",
    "        torch.cuda.empty_cache()\n",
    "        model.eval()\n",
    "#        loss = []\n",
    "#        frac = []\n",
    "\n",
    "        pred = []\n",
    "        true = []\n",
    "        loss= []\n",
    "        \n",
    "        correct = 0\n",
    "        predc = []\n",
    "        truec = []\n",
    "        for data in tqdm(testloader):\n",
    "            data = data.to(device)        \n",
    "            result = inv_transform(model(data))\n",
    "            truthv = inv_transform(data.genmass.flatten())\n",
    "            #print(\"eval result: \",result)\n",
    "            #print(\"original mass: \",truthv)\n",
    "            lossc = resoloss2(result, truthv)\n",
    "#            print (result.item(),data.y.item())\n",
    "#            frac.append((result.item() - data.y.item())/data.y.item())\n",
    "            loss.append(lossc.item())\n",
    "\n",
    "            for i in result:\n",
    "                pred.append(i.detach().cpu())\n",
    "                #predc.append(i.detach().cpu().argmax())\n",
    "            for i in truthv.detach():\n",
    "                true.append(i.detach().cpu())\n",
    "                #truec.append(i.detach().cpu())\n",
    "            \n",
    "            \n",
    "        #print(predc,truec)\n",
    "        #predc = np.array(predc)\n",
    "        #truec = np.array(truec)\n",
    "        #print(\"accuracy  :\",np.equal(predc,truec).sum()/len(truec))\n",
    "        \n",
    "        print('batches for test:', len(loss)) \n",
    "        print('test loss:',np.mean(np.array(loss)))\n",
    "#        fracarr = np.array(frac\n",
    "\n",
    "        \n",
    "        preda = np.array(pred)\n",
    "        truea = np.array(true)\n",
    "        #preda = preda[:,2] ### added\n",
    "        #truea = truea[:,1] ### added\n",
    "        fracarr = (preda - truea)/truea\n",
    "        #print(preda,truea,fracarr)\n",
    "        print('pred - true / true mean:',(np.mean(fracarr)))\n",
    "        print('pred - true / true std:',(np.std(fracarr)))\n",
    "        (mu, sigma) = norm.fit(fracarr)\n",
    "        print('mu,sig:',mu,sigma)\n",
    "        \n",
    "\n",
    "        #bin_heights, bin_borders, _ = plt.hist(fracarr,range=[-2,2], bins=100, label='histogram')\n",
    "        #bin_centers = bin_borders[:-1] + np.diff(bin_borders) / 2\n",
    "        \n",
    "        bins =  np.linspace(0,18,19)\n",
    "\n",
    "        fig, axs = plt.subplots(6,3, figsize=(40, 40), facecolor='w', edgecolor='k')\n",
    "        axs = axs.ravel()\n",
    "\n",
    "        for i in tqdm(range (bins.size - 1)):\n",
    "            predaa = preda[(truea >bins[i]) & (truea <bins[i+1]) ]\n",
    "            trueaa = truea[(truea >bins[i]) & (truea <bins[i+1]) ]\n",
    "            fracarr = (predaa - trueaa)/trueaa\n",
    "            #if (fracarr < 0):\n",
    "            axs[i].hist(fracarr,bins=100,range=[-4,4],)\n",
    "            axs[i].set_xlabel('pred - true / true')\n",
    "            axs[i].set_ylabel('counts')\n",
    "            axs[i].set_title(str(bins[i])+\" to \"+str(bins[i+1]))\n",
    "            #print (vals)\n",
    "        if (epoch%5==0):\n",
    "            plt.savefig('%s/mt-mp_frac_ep%d.png'%(plot_dir, epoch), bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        from matplotlib.pyplot import figure\n",
    "        figure(figsize=(30, 30), dpi=40)\n",
    "        #plt.rcParams['axes.labelsize'] = 36\n",
    "        #plt.rcParams['axes.titlesize'] = 36\n",
    "        #plt.hist2d(truea,preda,bins=200)\n",
    "        plt.scatter(truea,preda,alpha=0.4)\n",
    "        plt.plot([-4,18], [-4,18], 'k-')\n",
    "        plt.xticks(fontsize=16)\n",
    "        plt.yticks(fontsize=16)\n",
    "        plt.xlim([-2, 18])\n",
    "        plt.ylim([-2, 20])\n",
    "        plt.axvline(x=1.0,c='r')\n",
    "        plt.axhline(y=1.0,c='r')\n",
    "        #plt.show()\n",
    "        if (epoch%5 ==0):\n",
    "            plt.savefig('%s/mpredVsmtrue_ep%d.png'%(plot_dir, epoch), bbox_inches='tight')\n",
    "        plt.show()\n",
    "        return np.mean(np.array(loss))\n",
    "        #del pred,true,loss,preda,truea,fracarr  #memtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nepoch=500\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "best_loss = 99999999\n",
    "losst = []\n",
    "lossv = []\n",
    "epochs = []\n",
    "for epoch in range(nepoch):\n",
    "    print ('epoch:',epoch)\n",
    "    losst.append(train(epoch))\n",
    "    loss_epoch = evaluate(epoch)\n",
    "    lossv.append(loss_epoch)\n",
    "    epochs.append(epoch)\n",
    "    checkpoint = {\n",
    "    'epoch': epoch + 1,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    \n",
    "    checkpoint_file = 'model_epoch_%i.pth.tar' % ( epoch )\n",
    "    torch.save(checkpoint,\n",
    "                   os.path.join(checkpoint_dir,checkpoint_file ))\n",
    "    if loss_epoch < best_loss:\n",
    "        best_loss = loss_epoch\n",
    "        print('new best test loss:',best_loss)\n",
    "        torch.save(checkpoint,\n",
    "                   os.path.join(checkpoint_dir,'model_checkpoint_best.pth.tar' ))\n",
    "    if ((epoch+1)%10 == 0):\n",
    "        plt.plot(np.array(epochs),np.array(losst),c='b',label='training')\n",
    "        plt.plot(np.array(epochs),np.array(lossv),c='r',label='testing')\n",
    "        plt.legend()\n",
    "        if ((epoch+1) == nepoch):\n",
    "            plt.savefig('%s/TrainvsValLoss_ep%d.png'%(plot_dir, epoch), bbox_inches='tight')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
